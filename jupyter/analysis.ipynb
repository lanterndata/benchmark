{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97bea16-bf9a-4b8d-ac8a-eb6ae9b5e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists\n"
     ]
    }
   ],
   "source": [
    "# Download initial data\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "url = 'https://storage.googleapis.com/gresearch/wit/wit_v1.train.all-1percent_sample.tsv.gz'\n",
    "filename = 'data/wit/data.tsv'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    print(\"The file exists\")\n",
    "\n",
    "else:\n",
    "    # Download the data from the URL\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "      with open(filename + '.gz', 'wb') as f:\n",
    "        f.write(response.read())\n",
    "    \n",
    "    # Extract the data from the compressed file\n",
    "    with gzip.open(filename + '.gz', 'rb') as f_in:\n",
    "      with open(filename, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    print(\"The file was downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbc3aa6a-73e9-43fe-90ac-9efac1e748a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create table\n",
      "Copied data\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Create Postgres table with initial data\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "db_connection_string = os.environ.get('DATABASE_URL')\n",
    "conn = psycopg2.connect(db_connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "with open('data/wit/create_table.sql', 'r') as sql_file:\n",
    "    sql_script = sql_file.read()\n",
    "cursor.execute(sql_script)\n",
    "print(\"Create table\")\n",
    "\n",
    "count_query = \"SELECT COUNT(*) FROM tsv_data\"\n",
    "cursor.execute(count_query)\n",
    "row_count = cursor.fetchone()[0]\n",
    "\n",
    "if row_count == 0:\n",
    "    with open('data/wit/copy_data.sql', 'r') as sql_file:\n",
    "        sql_script = sql_file.read()\n",
    "    cursor.execute(sql_script)\n",
    "    print(\"Copied data\")\n",
    "else:\n",
    "    print(\"No need to copy data\")\n",
    "\n",
    "image_urls_query = \"SELECT id, image_url FROM tsv_data WHERE image_url_ai IS NULL LIMIT 10\"\n",
    "cursor.execute(image_urls_query)\n",
    "image_urls = cursor.fetchall()\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89300ae9-1a61-408d-9a1d-812f755051ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 220/500 [02:12<03:49,  1.22it/s]/usr/local/lib/python3.9/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [05:14<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import torch\n",
    "import clip\n",
    "import requests\n",
    "import PIL\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "db_connection_string = os.environ.get('DATABASE_URL')\n",
    "conn = psycopg2.connect(db_connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "cursor.execute('''\n",
    "    SELECT\n",
    "        id,\n",
    "        image_url\n",
    "    FROM\n",
    "        tsv_data\n",
    "    WHERE\n",
    "        language = 'en'\n",
    "        AND image_url IS NOT NULL\n",
    "    ORDER BY\n",
    "        RANDOM()\n",
    "    LIMIT 500\n",
    "''')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Set the batch size for database updates\n",
    "batch_size = 10\n",
    "\n",
    "# Initialize a buffer for batched updates\n",
    "update_buffer = []\n",
    "\n",
    "# Execute batched updates and clear the buffer\n",
    "def update_from_update_buffer():\n",
    "    update_query = \"UPDATE tsv_data SET image_url_ai = %s WHERE id = %s\"\n",
    "    cursor.executemany(update_query, update_buffer)\n",
    "    update_buffer.clear()\n",
    "\n",
    "# Process each tuple\n",
    "for item in tqdm(rows):\n",
    "    try:\n",
    "        # Unpack the tuple\n",
    "        id, image_url = item\n",
    "    \n",
    "        # Download the image from the URL\n",
    "        req_headers = {'User-Agent': 'SelectImages/0.0 (narekg.me; ngalstjan4@gmail.com)'}\n",
    "        response = requests.get(image_url, headers=req_headers)\n",
    "        image = PIL.Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
    "    \n",
    "        # Preprocess the image and generate embeddings\n",
    "        preprocessed_image = preprocess(image).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_embedding = model.encode_image(preprocessed_image).squeeze()\n",
    "    \n",
    "        # Add the updated row to the buffer\n",
    "        update_buffer.append((image_embedding.tolist(), id))\n",
    "    \n",
    "        # Execute batched updates when the buffer reaches the specified batch size\n",
    "        if len(update_buffer) >= batch_size:\n",
    "            update_from_update_buffer()\n",
    "\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "# Execute the remaining batched updates in the buffer\n",
    "if len(update_buffer) > 0:\n",
    "    update_from_update_buffer()\n",
    "    \n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and database connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f7e9b6-8f6b-4051-9f31-1f2aaef28630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:46<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "db_connection_string = os.environ.get('DATABASE_URL')\n",
    "conn = psycopg2.connect(db_connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "cursor.execute('''\n",
    "    SELECT\n",
    "        id,\n",
    "        context_page_description\n",
    "    FROM\n",
    "        tsv_data\n",
    "    WHERE\n",
    "        language = 'en'\n",
    "        AND context_page_description IS NOT NULL\n",
    "    ORDER BY\n",
    "        RANDOM()\n",
    "    LIMIT 500\n",
    "''')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Set the batch size for database updates\n",
    "batch_size = 10\n",
    "\n",
    "# Initialize a buffer for batched updates\n",
    "update_buffer = []\n",
    "\n",
    "# Execute batched updates and clear the buffer\n",
    "def update_from_update_buffer():\n",
    "    update_query = \"UPDATE tsv_data SET context_page_description_ai = %s WHERE id = %s\"\n",
    "    cursor.executemany(update_query, update_buffer)\n",
    "    update_buffer.clear()\n",
    "\n",
    "# Process each tuple\n",
    "for item in tqdm(rows):\n",
    "    try:\n",
    "        # Unpack the tuple\n",
    "        id, text = item\n",
    "    \n",
    "        # Tokenize the text and generate embeddings\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            text_embedding = torch.mean(outputs.last_hidden_state, dim=1).squeeze()\n",
    "    \n",
    "        # Add the updated row to the buffer\n",
    "        update_buffer.append((text_embedding.tolist(), id))\n",
    "    \n",
    "        # Execute batched updates when the buffer reaches the specified batch size\n",
    "        if len(update_buffer) >= batch_size:\n",
    "            update_from_update_buffer()\n",
    "\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "# Execute the remaining batched updates in the buffer\n",
    "if len(update_buffer) > 0:\n",
    "    update_from_update_buffer()\n",
    "    \n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and database connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da5ce55d-b7a2-4955-8734-3f98e3c08f6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedFunction",
     "evalue": "function vector(numeric[]) does not exist\nLINE 1: ...ERE image_url_ai IS NOT NULL AND image_url_ai <-> vector(ARR...\n                                                             ^\nHINT:  No function matches the given name and argument types. You might need to add explicit type casts.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedFunction\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m num_iterations \u001b[38;5;241m/\u001b[39m elapsed_time\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print(f\"select 1: {measure_throughput('SELECT 1')} OPS\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print(f\"select int: {measure_throughput('SELECT 1 FROM tsv_data WHERE image_url_ai IS NOT NULL AND original_height < 100' )} OPS\")\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpgvector: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmeasure_throughput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM tsv_data WHERE image_url_ai IS NOT NULL AND image_url_ai <-> vector(\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m) < 0.5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m OPS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     32\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m, in \u001b[0;36mmeasure_throughput\u001b[0;34m(query, generate_args)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     vector \u001b[38;5;241m=\u001b[39m generate_args()\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(query)        \n",
      "\u001b[0;31mUndefinedFunction\u001b[0m: function vector(numeric[]) does not exist\nLINE 1: ...ERE image_url_ai IS NOT NULL AND image_url_ai <-> vector(ARR...\n                                                             ^\nHINT:  No function matches the given name and argument types. You might need to add explicit type casts.\n"
     ]
    }
   ],
   "source": [
    "# What is pgvector throughput?\n",
    "\n",
    "import psycopg2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "db_connection_string = os.environ.get('DATABASE_URL')\n",
    "conn = psycopg2.connect(db_connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "num_iterations = 10\n",
    "\n",
    "def measure_throughput(query, generate_args=None):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        if generate_args is not None:\n",
    "            vector = generate_args()\n",
    "            cursor.execute(query, (vector,))\n",
    "        else:\n",
    "            cursor.execute(query)        \n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return num_iterations / elapsed_time\n",
    "\n",
    "# print(f\"select 1: {measure_throughput('SELECT 1')} OPS\")\n",
    "# print(f\"select int: {measure_throughput('SELECT 1 FROM tsv_data WHERE image_url_ai IS NOT NULL AND original_height < 100' )} OPS\")\n",
    "print(f\"pgvector: {measure_throughput('SELECT * FROM tsv_data WHERE image_url_ai IS NOT NULL AND image_url_ai <-> vector(%s) < 0.5', lambda: np.random.rand(500).tolist())} OPS\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b825267-c4d2-488a-a3c9-76156e0211a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
