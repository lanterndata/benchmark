{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97bea16-bf9a-4b8d-ac8a-eb6ae9b5e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists\n"
     ]
    }
   ],
   "source": [
    "# Download initial data\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "url = 'https://storage.googleapis.com/gresearch/wit/wit_v1.train.all-1percent_sample.tsv.gz'\n",
    "filename = 'data/wit/data.tsv'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    print(\"The file exists\")\n",
    "\n",
    "else:\n",
    "    # Download the data from the URL\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "      with open(filename + '.gz', 'wb') as f:\n",
    "        f.write(response.read())\n",
    "    \n",
    "    # Extract the data from the compressed file\n",
    "    with gzip.open(filename + '.gz', 'rb') as f_in:\n",
    "      with open(filename, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    print(\"The file was downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc3aa6a-73e9-43fe-90ac-9efac1e748a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create table\n",
      "No need to copy data\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Create Postgres table with initial data\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "db_connection_string = os.environ.get('DATABASE_URL')\n",
    "conn = psycopg2.connect(db_connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "with open('data/wit/create_table.sql', 'r') as sql_file:\n",
    "    sql_script = sql_file.read()\n",
    "cursor.execute(sql_script)\n",
    "print(\"Create table\")\n",
    "\n",
    "count_query = \"SELECT COUNT(*) FROM tsv_data\"\n",
    "cursor.execute(count_query)\n",
    "row_count = cursor.fetchone()[0]\n",
    "\n",
    "if row_count == 0:\n",
    "    with open('data/wit/copy_data.sql', 'r') as sql_file:\n",
    "        sql_script = sql_file.read()\n",
    "    cursor.execute(sql_script)\n",
    "    print(\"Copied data\")\n",
    "else:\n",
    "    print(\"No need to copy data\")\n",
    "\n",
    "image_urls_query = \"SELECT id, image_url FROM tsv_data WHERE image_url_ai IS NULL LIMIT 10\"\n",
    "cursor.execute(image_urls_query)\n",
    "image_urls = cursor.fetchall()\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89300ae9-1a61-408d-9a1d-812f755051ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/10000 [00:02<1:32:36,  1.80it/s]"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import torch\n",
    "import clip\n",
    "import requests\n",
    "import PIL\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "db_connection_string = os.environ.get('DATABASE_URL')\n",
    "conn = psycopg2.connect(db_connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "cursor.execute('''\n",
    "    SELECT\n",
    "        id,\n",
    "        context_page_description,\n",
    "        image_url\n",
    "    FROM\n",
    "        tsv_data\n",
    "    WHERE\n",
    "        language = 'en'\n",
    "        AND context_page_description IS NOT NULL\n",
    "        AND image_url IS NOT NULL\n",
    "    LIMIT 10000\n",
    "''')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Set the batch size for database updates\n",
    "batch_size = 100\n",
    "\n",
    "# Initialize a buffer for batched updates\n",
    "update_buffer = []\n",
    "\n",
    "# Execute batched updates and clear the buffer\n",
    "def update_from_update_buffer():\n",
    "    cursor.executemany(\n",
    "        \"UPDATE tsv_data SET image_url_ai = %s, context_page_description_ai = %s WHERE id = %s\",\n",
    "        update_buffer\n",
    "    )\n",
    "    update_buffer.clear()\n",
    "\n",
    "# Process each tuple\n",
    "for item in tqdm(rows):\n",
    "    # Unpack the tuple\n",
    "    id, summary, image_url = item\n",
    "\n",
    "    # Download the image from the URL\n",
    "    req_headers = {'User-Agent': 'SelectImages/0.0 (narekg.me; ngalstjan4@gmail.com)'}\n",
    "    response = requests.get(image_url, headers=req_headers)\n",
    "    image = PIL.Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "    # Preprocess the image and summary\n",
    "    preprocessed_image = preprocess(image).unsqueeze(0).to(device)\n",
    "    preprocessed_summary = clip.tokenize(summary, truncate=True).to(device)\n",
    "\n",
    "    # Generate image and summary embeddings\n",
    "    with torch.no_grad():\n",
    "        image_embedding = model.encode_image(preprocessed_image).squeeze()\n",
    "        summary_embedding = model.encode_text(preprocessed_summary).squeeze()\n",
    "\n",
    "    # Add the updated row to the buffer\n",
    "    update_buffer.append((image_embedding.tolist(), summary_embedding.tolist(), id))\n",
    "\n",
    "    # Execute batched updates when the buffer reaches the specified batch size\n",
    "    if len(update_buffer) >= batch_size:\n",
    "        update_from_update_buffer()\n",
    "\n",
    "# Execute the remaining batched updates in the buffer\n",
    "if len(update_buffer) > 0:\n",
    "    update_from_update_buffer()\n",
    "    \n",
    "\n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and database connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
